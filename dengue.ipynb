{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# just for the sake of this blog post!\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data_path, labels_path=None):\n",
    "    # load data and set index to city, year, weekofyear\n",
    "    df = pd.read_csv(data_path, index_col=[0, 1, 2])\n",
    "    \n",
    "    # select features we want\n",
    "    features = ['reanalysis_specific_humidity_g_per_kg', \n",
    "                 'reanalysis_dew_point_temp_k', \n",
    "                 'station_avg_temp_c', \n",
    "                 'station_min_temp_c',\n",
    "                 'reanalysis_max_air_temp_k',\n",
    "                 'station_max_temp_c',\n",
    "                 'reanalysis_min_air_temp_k',\n",
    "                 'reanalysis_air_temp_k']\n",
    "    df = df[features]\n",
    "    \n",
    "    # fill missing values\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    #df.interpolate(\"linear\")\n",
    "    # mark zero values as missing or NaN\n",
    "    #df[[0,1,2,3,4]] = df[[0,1,2,3,4]].replace(0, np.NaN)\n",
    "    # fill missing values with mean column values\n",
    "    #df.fillna(df.median(), inplace=True)\n",
    "    \n",
    "    # add labels to dataframe\n",
    "    if labels_path:\n",
    "        labels = pd.read_csv(labels_path, index_col=[0, 1, 2])\n",
    "        df = df.join(labels)\n",
    "    \n",
    "    # separate san juan and iquitos\n",
    "    sj = df.loc['sj']\n",
    "    iq = df.loc['iq']\n",
    "    \n",
    "    return sj, iq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_train, iq_train = preprocess_data('data-processed/dengue_features_train.csv',\n",
    "                                    labels_path=\"data-processed/dengue_labels_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_train_subtrain = sj_train.head(800)\n",
    "sj_train_subtest = sj_train.tail(sj_train.shape[0] - 800)\n",
    "\n",
    "iq_train_subtrain = iq_train.head(400)\n",
    "iq_train_subtest = iq_train.tail(iq_train.shape[0] - 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha =  0.0001\n",
      "best score =  22.5661764706\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tools import eval_measures\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def get_best_model(train, test):\n",
    "    # Step 1: specify the form of the model\n",
    "    model_formula = \"total_cases ~ 1 + \" \\\n",
    "                    \"reanalysis_specific_humidity_g_per_kg + \" \\\n",
    "                    \"reanalysis_dew_point_temp_k + \" \\\n",
    "                    \"station_max_temp_c + \" \\\n",
    "                    \"station_avg_temp_c +\" \\\n",
    "                    \"reanalysis_max_air_temp_k +\" \\\n",
    "                    \"reanalysis_min_air_temp_k\"\n",
    "    \n",
    "    grid = 10 ** np.arange(-8, -3, dtype=np.float64)\n",
    "                    \n",
    "    best_alpha = []\n",
    "    best_score = 1000\n",
    "        \n",
    "    # Step 2: Find the best hyper parameter, alpha\n",
    "    for alpha in grid:\n",
    "        model = smf.glm(formula=model_formula,\n",
    "                        data=train,\n",
    "                        family=sm.families.NegativeBinomial(alpha=alpha))\n",
    "\n",
    "        results = model.fit()\n",
    "        predictions = results.predict(test).astype(int)\n",
    "        score = eval_measures.meanabs(predictions, test.total_cases)\n",
    "\n",
    "        if score < best_score:\n",
    "            best_alpha = alpha\n",
    "            best_score = score\n",
    "\n",
    "    print('best alpha = ', best_alpha)\n",
    "    print('best score = ', best_score)\n",
    "            \n",
    "    # Step 3: refit on entire dataset\n",
    "    full_dataset = pd.concat([train, test])\n",
    "    model = smf.glm(formula=model_formula,\n",
    "                    data=full_dataset,\n",
    "                    family=sm.families.NegativeBinomial(alpha=best_alpha))\n",
    "\n",
    "    fitted_model = model.fit()\n",
    "    return fitted_model\n",
    "    \n",
    "sj_best_model = get_best_model(sj_train_subtrain, sj_train_subtest)\n",
    "#iq_best_model = get_best_model(iq_train_subtrain, iq_train_subtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha =  1e-08\n",
      "best score =  6.475\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tools import eval_measures\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def get_best_model_new(train, test):\n",
    "    # Step 1: specify the form of the model\n",
    "    model_formula = \"total_cases ~ 1 + \" \\\n",
    "                    \"reanalysis_specific_humidity_g_per_kg + \" \\\n",
    "                    \"reanalysis_dew_point_temp_k + \" \\\n",
    "                    \"station_min_temp_c + \" \\\n",
    "                    \"reanalysis_min_air_temp_k\"\n",
    "    \n",
    "    grid = 10 ** np.arange(-8, -3, dtype=np.float64)\n",
    "                    \n",
    "    best_alpha = []\n",
    "    best_score = 1000\n",
    "        \n",
    "    # Step 2: Find the best hyper parameter, alpha\n",
    "    for alpha in grid:\n",
    "        model = smf.glm(formula=model_formula,\n",
    "                        data=train,\n",
    "                        family=sm.families.NegativeBinomial(alpha=alpha))\n",
    "\n",
    "        results = model.fit()\n",
    "        predictions = results.predict(test).astype(int)\n",
    "        score = eval_measures.meanabs(predictions, test.total_cases)\n",
    "\n",
    "        if score < best_score:\n",
    "            best_alpha = alpha\n",
    "            best_score = score\n",
    "\n",
    "    print('best alpha = ', best_alpha)\n",
    "    print('best score = ', best_score)\n",
    "            \n",
    "    # Step 3: refit on entire dataset\n",
    "    full_dataset = pd.concat([train, test])\n",
    "    model = smf.glm(formula=model_formula,\n",
    "                    data=full_dataset,\n",
    "                    family=sm.families.NegativeBinomial(alpha=best_alpha))\n",
    "\n",
    "    fitted_model = model.fit()\n",
    "    return fitted_model\n",
    "\n",
    "iq_best_model = get_best_model_new(iq_train_subtrain, iq_train_subtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_test, iq_test = preprocess_data('data-processed/dengue_features_test.csv')\n",
    "\n",
    "sj_predictions = sj_best_model.predict(sj_test).astype(int)\n",
    "iq_predictions = iq_best_model.predict(iq_test).astype(int)\n",
    "\n",
    "submission = pd.read_csv(\"data-processed/submission_format.csv\",\n",
    "                         index_col=[0, 1, 2])\n",
    "\n",
    "submission.total_cases = np.concatenate([sj_predictions, iq_predictions])\n",
    "submission.to_csv(\"data-processed/benchmark.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
